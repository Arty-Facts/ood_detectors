{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"results.yaml\"\n",
    "\n",
    "with open(file, \"r\") as f:\n",
    "    results = yaml.load(f, Loader=yaml.FullLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multicol(name, space=2, bars=False):\n",
    "    if bars:\n",
    "        return r\"\\multicolumn{\" +str(space)+r\"}{|c|}{\\textbf{\" + name + r\"}}\"\n",
    "    return r\"\\multicolumn{\" +str(space)+r\"}{c}{\\textbf{\" + name + r\"}}\"\n",
    "\n",
    "def get_names(data):\n",
    "    far_names = []\n",
    "    near_names = []\n",
    "    for _type, datasets in data.items():\n",
    "        if _type == \"farood\":\n",
    "            for dataset in datasets:\n",
    "                far_names.append(dataset[\"dataset\"])\n",
    "        elif _type == \"nearood\":\n",
    "            for dataset in datasets:\n",
    "                near_names.append(dataset[\"dataset\"])\n",
    "\n",
    "    return far_names, near_names\n",
    "\n",
    "def create_latex_table(result, method, dataset, encoders):\n",
    "    data = result[method][encoders[0]][dataset]\n",
    "    far_names, near_names = get_names(data)\n",
    "\n",
    "    total_items = len(far_names) + len(near_names)\n",
    "\n",
    "    header = r\"\\begin{table}[ht]\"+ \"\\n\"\n",
    "    header += r\"\\caption{\" +f\"Result for {method} using {dataset}\" + r\"}\"+ \"\\n\"\n",
    "\n",
    "    header += r\"\"\"\\centering\n",
    "\\resizebox{\\textwidth}{!}{% Resize table to fit within \\textwidth horizontally\n",
    "\"\"\"\n",
    "    header += r\"\\begin{tabular}{@{}l*{\" + str(total_items) + r\"}{SS}@{}}\" + \"\\n\"\n",
    "    header += r\"\\toprule\" + \"\\n\"\n",
    "\n",
    "    description = r\"\\textbf{Encoder} & \"  + \" & \".join(multicol(name.replace(\"_\", r\"\\_\")) for name in far_names + near_names) + r\" \\\\\" + \"\\n\"\n",
    "    description +=  r\" & {\\footnotesize AUROC} $\\uparrow$ & {\\footnotesize FPR95} $\\downarrow$ \"*total_items + r\" \\\\\" + \"\\n\"\n",
    "    midrule = r\"\\midrule\" + \"\\n\"\n",
    "    footer = r\"\\label{tab:\" + f\"{method}_{dataset}\" + r\"}\" + \"\\n\"\n",
    "    footer += r\"\"\"\n",
    "\\bottomrule\n",
    "\\end{tabular}\n",
    "}\n",
    "\\end{table}\n",
    "\"\"\"+\"\\n\"\n",
    "\n",
    "    rows = [\" & \"   + multicol(\"Near OOD\", len(near_names)*2, True) + \" & \" + multicol(\"Far OOD\", len(far_names)*2, True) + r\" \\\\\" + \"\\n\"]\n",
    "    # rows = []\n",
    "\n",
    "    lookup = {}\n",
    "    max_data = {}\n",
    "    for encoder in sorted(encoders):\n",
    "        if encoder not in result[method]:\n",
    "            continue\n",
    "        if dataset not in result[method][encoder]:\n",
    "            continue\n",
    "        for name, data in result[method][encoder][dataset].items():\n",
    "            if name not in [\"nearood\", \"farood\"]:\n",
    "                continue\n",
    "            lookup_tmp = {d[\"dataset\"]: d[\"metrics\"] for d in data}\n",
    "            if encoder not in lookup:\n",
    "                lookup[encoder] = {}\n",
    "            lookup[encoder].update(lookup_tmp)\n",
    " \n",
    "    for e in encoders:\n",
    "        if e not in lookup:\n",
    "            continue\n",
    "        for data_name in lookup[e]:\n",
    "            if data_name not in lookup[e]:\n",
    "                continue\n",
    "            if data_name not in max_data:\n",
    "                max_data[data_name] = {\n",
    "                    \"AUC\": 0,\n",
    "                    \"FPR_95\": 1\n",
    "                }\n",
    "            if lookup[e][data_name][\"AUC\"] > max_data[data_name][\"AUC\"]:\n",
    "                max_data[data_name][\"AUC\"] = lookup[e][data_name][\"AUC\"]\n",
    "            if lookup[e][data_name][\"FPR_95\"] < max_data[data_name][\"FPR_95\"]:\n",
    "                max_data[data_name][\"FPR_95\"] = lookup[e][data_name][\"FPR_95\"]\n",
    "\n",
    "    for encoder in sorted(encoders):\n",
    "        if encoder not in result[method]:\n",
    "            continue\n",
    "        if dataset not in result[method][encoder]:\n",
    "            continue\n",
    "        if \"resnet18_\" in encoder:\n",
    "            row = [r\"resnet18\\_open\\_ood\"]\n",
    "        elif \"resnet50_\" in encoder:\n",
    "            row = [r\"resnet50\\_open\\_ood\"]\n",
    "        else:\n",
    "            row = [encoder]\n",
    "        for data_names in far_names + near_names:\n",
    "            data_res = max_data[data_names]\n",
    "            max_auc = data_res[\"AUC\"]\n",
    "            min_fpr = data_res[\"FPR_95\"]\n",
    "            if data_names in lookup[encoder]:\n",
    "                metrics = lookup[encoder][data_names]\n",
    "                if metrics[\"AUC\"] == max_auc:\n",
    "                    row.append(r\"\\textbf{\" + f\"{metrics['AUC']*100:.2f}\" + r\"}\")\n",
    "                else:\n",
    "                    row.append(f\"{metrics['AUC']*100:.2f}\")\n",
    "                if metrics[\"FPR_95\"] == min_fpr:\n",
    "                    row.append(r\"\\textbf{\" + f\"{metrics['FPR_95']*100:.2f}\" + r\"}\")\n",
    "                else:\n",
    "                    row.append(f\"{metrics['FPR_95']*100:.2f}\")\n",
    "            else:\n",
    "                row.append(\"-\")\n",
    "                row.append(\"-\")\n",
    "                    \n",
    "        rows.append(\" & \".join(row) + r\" \\\\\")\n",
    "\n",
    "    return header + description + midrule + \"\\n\".join(rows) + footer\n",
    "\n",
    "# Generate the LaTeX table\n",
    "datasets = ['imagenet200', 'cifar10', 'cifar100', 'covid', 'mnist']\n",
    "encoders = ['repvgg', 'resnet50d', 'swin', 'deit', 'dino', 'dinov2', 'vit', 'clip'] + ['resnet18_32x32_cifar10_open_ood', 'resnet18_32x32_cifar100_open_ood', 'resnet18_224x224_imagenet200_open_ood', 'resnet50_224x224_imagenet_open_ood']\n",
    "with open(\"out.txt\", \"w\") as f:\n",
    "    for method, result in results.items():\n",
    "        for dataset in datasets:\n",
    "            f.write(create_latex_table(results, method, dataset, encoders))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
